---
layout: post
title:  传智播客-深度学习入门
date:   2020-06-10 00:00:00 +0800
categories: 传智播客
tag: 传智播客
---

* content
{:toc}


## 课程导学

Hello 同学你好，我是杰森老师。欢迎你今天可以跟我一起来探索深度学习的奥秘。我相信打开这门课的你一定听说过人工智能这个词汇，没听过也不要紧～但是你一定知道一些人工智能在现实中的应用。不信？我来举几个你一定知道的例子：

来，打开手机，你的照相机有没有自动美颜？对的，这些所谓的美颜，还有前段时间火过一时的看看自己老年相貌小应用，这些样貌的生成其实都是人工智能的杰作。

<p align="center"> 
  <img src="/imgs/czbkpics/1.jpg">
</p>

再来举一个例子。百度翻译、有道翻译、谷歌翻译你肯定用过吧，这可不是程序猿一句一句先录入答案的然后再通过你给的句子找到对应的答案哦。它们的背后都是一个人工智能模型在接收我们的输入，然后通过一些神奇的算法再把它觉得最有可能的结果告诉我们。

<p align="center"> 
  <img src="/imgs/czbkpics/2.png">
</p>

你看，其实人工智能已经默默地潜入到我们的生活了，它可以更好的帮助我们完成我们的目的，让我们的生活变得更加轻松自如。

如今越来越多的岗位逐渐被人工智能取代，但是不用怕，人工智能也为我们创造了更多的岗位，不仅不用害怕找不到工作，而且“钱途”很大有木有～

<p align="center"> 
  <img src="/imgs/czbkpics/3.png">
</p>

只要你跟着老师上完本次课程，你将会入门人工智能并且可以自己开发一个人工智能系统！




在开发系统前，我们首先看看我们都需要哪些前置知识：
1. 了解深度学习的概念及应用
2. 了解都有哪些深度学习的模型
3. 了解有哪些工具可以帮助我们构建深度学习模型
4. 我们要学会如何使用这些工具
5. It's ready to 开发自己的深度学习模型！！！

## 第一关 石猴出世

#### 1.1 深度学习的概念

我们之前提到的都是人工智能，但是要注意人工智能不等于深度学习哦。今日头条为我们绘制了一个图谱。通常来说人工智能包括机器学习、深度学习、强化学习。它们之间有一定的交集但是我们一定要区分开它们。

<p align="center"> 
  <img src="/imgs/czbkpics/5.jpg">
</p>

我们所说的深度学习是指由**多层人工神经网络**所架构的模型。我们在完成一个任务的时候肯定要有的就是输入和输出，比如机器翻译中我们输入中文，输出英文。在神经网络中，我们把它们叫做输入层和输出层。从输入层到输出层之间还会有很多层用来计算，它们负责如何把输入转化为输出。这些中间层我们称为“隐含层”。如果一个神经网络含有**多个**（大于1个）隐含层，我们就管这个网络叫深度神经网络，学习这个模型的过程也就叫做深度学习。因为它在各项任务中表现突出，在越复杂的任务中往往比普通机器学习模型强悍越多，所以日益发展壮大，独成一派。

#### 1.2 深度学习的发展史

我们知道深度学习模型是由深度神经网络架构而成的，神经网络诞生于1943年，但是那个时候因为计算机硬件的落后，更多的概念仅仅停留在学术层面。随着计算机处理器的计算速度和存储越来越强大，在1957-1958年，终于把单层神经网络用在了人工智能应用（模式识别）上，实现了神经网络的第一次兴起。在1986年迎来了两层神经网络，实现了第二次兴起。但是后来又因为CPU算力的不足，人们把精力都放在了普通机器学习模型上，比如KNN，决策树，梯度提升树等。终于到了2012年卷积神经网络的诞生，在ImageNet竞赛中秒杀所有普通机器学习模型，迎来了多层神经网络的时代并开启第三次兴起。

<p align="center"> 
  <img src="/imgs/czbkpics/4.png">
</p>

很荣幸，同学，我们现在就处在神经网络第三次兴起的兴盛阶段！所以人工智能在我们的生活中是随处可见的。

#### 1.3 深度学习随处可见

我们通常把一个学习任务分成两类，关于图片的学习，和关于语言/语音的学习。

关于图片的学习我们叫做计算机视觉，如今的应用也是随处可见。在商业中比如人脸识别，指纹解锁，虹膜认证，自动驾驶，还有对视频内容的提取。比如如火如荼的自动驾驶，它会帮助你把摄像头拍到的路况做一个处理，告诉你你要是再不刹车可能就要撞电线杆啦！这时候刹车系统接收到这种警告后会采取减速或者刹车处理。

在医学中比如肿瘤的识别，健康状况的监控，手术机器人等。毕竟人的视力范围有限，在手术中有一个可以眼观六路的机器人当然会极大的帮到我们的医生。

<p align="center"> 
  <img src="/imgs/czbkpics/6.jpeg">
</p>

关于语言的学习我们称为自然语言处理。在商业中比如机器翻译、情感分析、文章摘要提取等。比如我们在社交媒体中发布一条评论，在app的后台你的这条消息会通过很多层的过滤，如果一旦发现有涉及危险信息或者不良信息的短语或语句，会直接吞掉拒绝你的评论～

在医学中，比如可以通过患者对病情和病史的叙述，提取出关键信息，辅助医生为病情作判断。甚至可以帮助到那些偏远地区和贫困家庭享受到和大医院同等的诊断水平。

此刻相信你已经心里有谱了，老师邀请你跟随我一起走进深度学习的世界，并且我们要仅用xxxxx行代码实现自己的深度学习模型！



## 闯关练习

1. 下列选项中属于深度学习的模型是：

> A. 单隐含层神经网络
> B. 梯度上升树
> C. KNN
> D. 多隐含层神经网络

正确答案：D，我们管由多个隐含层组成的神经网络叫做深度学习模型。

2. 下列描述中正确的是：

> A. 人工智能包括深度学习
> B. 机器学习包括深度学习
> C. 神经网络包括深度学习
> D. 机器学习不包括神经网络

正确答案：C， 由AI知识图谱我们可以看到，深度学习是完全属于神经网络领域内的。



## 第二关 刨根问底


#### 2.1 神经元

我相信神经元这个词汇同学你肯定听说过，如果你还知道神经元在我们大脑里有联络和整合输入信息并传出信息的作用的话，恭喜你，你已经掌握了人工神经网络的精髓！是的，在1943年的两位神经学家沃伦和逻辑学家沃尔特就发现既然计算机不如我们的大脑，那我们能不能让计算机也模仿大脑进行工作，最起码也要跟我们的大脑一样强嘛！所以他们把动物大脑中的神经网络原封不动地搬到了数学模型中。所以在他们的模型里面，一个简单的人工节点，我们就称为神经元。再后来1958年Frank Rosenblatt觉得这个思想完全可以创造一个可以识别物体的机器啊，就创建了一套算法，后来人们把这套算法叫做“感知机”。

从此人工神经网络这门学科也被人们称为“仿生学”。

好了，我们的项目中现在已经有了神经元这个小家伙，它能帮助我们对输入的信息进行整合并且输出传递给下一个神经元。
就好比我们的眼睛看到的物体，通过一连串的神经元排排坐，一个转告另一个：

神经元A对神经元B说：“喂，老师看到了一个物体，它头发很长，大大的眼睛，还咧着嘴。” 神经元B整合信息之后对神经元C说：“喂，老师看到了一个大眼睛的女生，好像还在笑。” 神经元C再整合信息对神经元D说：“喂，老师看到一个爱笑的大眼睛女生！” 最终传递到大脑，大脑说：“行了我知道了，哎他又看到美女了。”

此时老师拍拍旁边的哥们：“诶你看，美女诶！”

我们管眼睛看到了物体形状叫做输入，这个输入可能会很零散，零散到像一堆乐高拼图碎片你根本看不出来它是什么，随着神经元的辛勤整合和传递，我们才能在大脑中产生输出，来判断眼睛看到的是个什么～

此刻在你大脑里的神经网络应该是这样的：

<p align="center"> 
  <img src="/imgs/czbkpics/7.png">
</p>


可是我们现在只是把输入给到了一个神经元A，可是我们的眼睛看到一个物体是由很多个神经元共同接收信息的呀？
好，那我们就一起再设计另一个网络。

#### 2.2 单层神经网络

还记得我们说过人们把Frank Rosenblatt设计的一套算法叫做感知机嘛，单层神经网络我们也叫做单层感知机。顾名思义，既然是单层，那就是只有一层。如果回到我们上一个老师看美女的例子中，那么单层也就意味着只有神经元A的存在。可是我们之前有个疑问，就是我们看到一个物体明明是由很多个神经元参与的，不可能只有一个神经元A啊。好，那么我们现在把神经元A多复制几份：

<p align="center"> 
  <img src="/imgs/czbkpics/8.png">
</p>

我们照样还是有一个输入，有一个大脑作为输出，在他们之间我们有一列的神经元排排坐，和上一个例子的区别是这回它们不能沟通！A1不能把自己看到的东西偷偷告诉A2！它们只能把自己看到的东西直接告诉大脑！现在的情况就变成了：

神经元A1发现老师正在看到的物体有长长的头发，便对大脑说：“老师看到了长长的头发！”
神经元A2发现老师正在看到的物体有大大的眼睛，便对大脑说：“老师看到了大大的眼睛！”
神经元A3发现老师正在看到的物体正在咧着嘴，便对大脑说：“老师看到了物体咧着嘴！”
大脑接收到了神经元们的通知说：“行了我知道了，哎他又看到美女了。”

此时老师又拍拍旁边的哥们：“诶你看，又一个美女诶！”

这种情况下，我们管中间的那一列神经元们叫做一层，所以由输入（眼睛）->一层神经元们->输出（大脑）这样的组合我们就叫做单层神经网络，也叫单层感知机。

是不是很简单，但是别看它的结构很简单，它的能力是很强的。在数学中它还有一套定理叫做“万能近似定理”，指的是如果你手头上有一个包含一层神经元的网络结构，只要你这一层有足够多的神经元排排坐（例如有50个/100个/...），那么你这个神经网络就可以做到任何的事情！

厉害吧，可是如果你对神经网络有所了解或者你偷偷看到了后面的内容，就不禁会有一个疑问：既然单层神经网络已经这么厉害了，我们为什么还要有多层神经网络呢？

为了解释这个疑问，我们要引入神经网络“参数”这个概念。打个比方，老师在上次看到美女的超市买菜，走到草莓摊位前问老板：“老板你这草莓咋卖啊？” 老板说：“10块钱1公斤，20块钱2公斤。30块钱3公斤。” “害，老板你直接说每公斤10块钱不就好了嘛！”

我们把这个场景用神经网络代替一下，输入是10块钱、20块钱、30块钱，输出是1公斤、2公斤和3公斤，那么中间的神经元怎么去转化这个呢？没错就是把输入除以单价10就好了，当我们发现了这个规律之后，无论你告诉我你要买多少钱的草莓我都能算出来你买的多少公斤。神经网络的参数，就是那个单价10。

神经网络做的事情，就是把我们人类不能在脑子里计算出来的参数，帮助我们计算出来。

好了，回到之前的问题。既然一层够强大，为啥需要多层？原因很简单：我们知道了神经网络就是在学习所谓的参数，我发誓你用单层一定可以学习到最好的参数，但是我又没说你肯定能学到。换句话说，我保证你有一生赚够一千万的能力，但是我又没说你一定能做到。。

一万匹草泥马呼啸而过。OK吧，那既然我一个人未必能达到，我找几个小伙伴组团就简单很多了吧，一千万的目标岂不是很容易。

#### 2.3 多层神经网络

顾名思义，我们此时选中第一层神经元A1-A3，右键复制粘贴重命名为神经元B1-B3:

<p align="center"> 
  <img src="/imgs/czbkpics/9.png">
</p>

每一层的神经元我们让它都跟下一层的所有神经元相连接。此时我们已经有了一个2层神经网络。我们当然还可以再多复制几层，可是

## 闯关练习

1. 在神经网络中每个神经元的作用是什么？（多选题）

> A. 接收传递过来的信息
> B. 保存参数
> C. 发送整合后的信息给下一个神经元
> D. 信息整合

正确答案：A,C,D 神经元的作用是接收前面神经元传递过来的信息并且整合之后再传递给下一个神经元。


2. 在单层神经网络中，下面表述正确的是：

> A. 一层中每个神经元相互连接
> B. 有学习到最佳参数的能力
> C. 没有学习到最佳参数的能力
> D. 一定不如多层神经网络

正确答案：B 无论是几层的网络，同一层的神经元之间不相互连接；单层神经网络有学习到最佳参数的能力；神经网络的好坏不取决于有多少层，10层的神经网络未必就有1层的神经网络好。

3. 在多层神经网络中，下面表述错误的是：

> A. 每个神经元只跟下一层的某个神经元相连
> B. 网络的参数可以用梯度下降法来求解
> C. 第i层的某个神经元接收自i-1层所有的神经元传递来的信息
> D. 梯度下降法求解只能求得近似解

正确答案：A 每个神经元都跟下一层的所有神经元相连接。梯度下降法是用迭代的方式一步一步的逼近真实解，所以大多数情况下我们只能得到近似解。


## 第三关 知己知彼

#### 3.1 卷积神经网络



