---
layout: post
title:  凸优化
date:   2020—05-24 00:00:00 +0800
categories: 机器学习
tag: 凸优化
---

* content
{:toc}


<h2 align="center">宏观理解</h2>

Optimization is the core of Machine Learning！<br/>
对于每个人工智能问题，都是在解决模型和优化这两个难点。所以对于训练模型来说，在做的就是找到模型参数，这个过程就是通过优化算法。比如说SVM就是一个凸优化问题。
对于所有的优化问题，我们都可以写成要Minimize f(x)的形式，f就是目标函数。他也可能会有一些限制条件，比如目标函数中的某些算式是小于等于0的，或等于0的。也就是一个是不等式约束，一个是等式约束。
对于任何其他种类的目标函数，也都是可以改造成这个形式。<br/>
对于优化问题我们可以分为4个种类：
 - 凸函数convex        **vs**      非凸函数non-convex
 - 连续的continues     **vs**      离散的discrete
 - 有约束constrained   **vs**      无约束的non-constrained
 - 平滑的smooth        **vs**      不平滑的non-smooth
<br/>
其中最简单的优化问题就是凸函数、连续的、没有约束并且是平滑的。
<br/>
我们本次只讨论凸函数的优化。

<h2 align="center">微观分析</h2>

我们想把一个复杂的问题变成可以进行凸优化的问题是因为凸函数只有一个local optimal，也就是global optimal。
对于非凸函数的优化，就会有很多个局部最优解，不一定可以找到全局最优解。所以如果碰到了非凸函数的优化问题，比如说深度学习，
我们往往会追求一个更好的局部最优解。所以对于深度学习来说，模型的预训练变得非常重要，因为一个好的预训练可以帮助你找到更好的local optimal。
或者我们可以尝试把一个非凸函数松弛(relax)成一个凸函数。甚至如果数据很小，也可以去尝试暴力解决。

<h3>什么是凸集？</h3>

对于一个优化问题，我们都可以写成如下形式：

<p align="center" > 
  <img src="/imgs/convex/1.png" width="50%" height="50%">
</p>

其中s.t.代表这个函数会有的约束条件。我们管x叫做定义域，管f(x)叫做值域，也就是所有可能的取值范围。

再来我们先规定一些定义，在下图中，值域是被x1和x2所约束的，也就是有两个约束条件，那么在这两个约束条件内的区域称为可行域feasible region，也就是这里面
的所有x取值都是满足这个函数的。再来，在这个可行域内的某个点我们叫做可行解feasible solution。在这些可行解中，存在最佳的一个解，叫做最优解optimal solution。

<p align="center"> 
  <img src="/imgs/convex/2.jpg" width="50%" height="50%">
</p>

那么在定义域中，我们任选了两个点，如果对于这两个点x，y存在一个alpha值属于[0,1]，我们有![](https://latex.codecogs.com/gif.latex?%5Calpha%20x&plus;%281-%5Calpha%20%29y%5Cin%20C)
，则这个集合叫做凸集convex set。则在下图中属于凸集的是(A）

<p align="center"> 
  <img src="/imgs/convex/3.gif" width="50%" height="50%">
</p>

还有一些定理比如两个凸集的交集也是凸集。

<h3>什么是凸函数？</h3>

凸函数的定义为在该函数的凸集定义域内任意两个点x，y，函数满足![](https://latex.codecogs.com/gif.latex?f%28%5Ctheta%20x%20&plus;%20%281-%5Ctheta%20%29y%29%20%5Cleq%20%5Ctheta%20f%28x%29&plus;%281-%5Ctheta%20%29f%28y%29)
。用人话说，就是函数内任意两个点的连线中的convex combination一定在定义域上convex combination的上方。

<p align="center"> 
  <img src="/imgs/convex/4.png" width="50%" height="50%">
</p>

那么我们在拿到一个函数的时候怎么去判断他是不是一个凸函数呢？<br/>
- 根据First order convexity condition, 我们首先要求函数f是可导的，并且对于任意的x，y当且仅当满足![](https://latex.codecogs.com/gif.latex?f%28y%29%5Cgeq%20f%28x%29&plus;%5Ctriangledown%20%28x%29%5ET%28y-x%29)
时，f为凸函数。
- 根据Second order convexity condition, 我们首先要求函数f是二阶可导的，并且对于任意的x，y当且仅当满足![](https://latex.codecogs.com/gif.latex?%5Ctriangledown%5E2%20f%28x%29%5Csucceq%200)
时，f为凸函数。

常见的凸优化问题比如线性规划，则可以使用很多在线solver可以解决。

那么我们对于一般无约束的最优化问题都很好解决，比如![](https://latex.codecogs.com/gif.latex?f%28x%2Cy%29%20%3D%20x%5E2%20&plus;%20y%5E2%20-2x)
，我们只要求出x对于f的导数等于0的时候x的值，和y对于f的导数等于0的时候y的值便能得到整个函数的最小值。可是如果像文章刚开头的凸优化问题标准形式，带有约束条件时，就
会变得棘手，所以如何把带有约束条件的最优化问题转变成无约束条件的最优化问题呢？

<h3>拉格朗日对偶</h3>

这时候我们就需要引入一个辅助函数，叫广义拉格朗日函数generalized lagrange function，之所以叫广义，就是它并不会对优化问题的函数和约束条件进行某种限定，接受任何形式的约束。

<p align="center"> 
  <img src="/imgs/convex/5.png">
</p>

其中x即为原函数中的x值，alpha是一个k维向量，每个alpha对应一个非不等式约束，也就是说对于每一个ci我们都有一个alpha_i。相似的，对于每一个等式约束我们都有一个对应的beta_j。

我们还需要一个辅助函数：

<p align="center"> 
  <img src="/imgs/convex/6.png" width="50%" height="50%">
</p>

对于任何的x，我们都可以用theta_p函数来求得一个值，这个值我们可以通过确定拉格朗日函数的x值时，求得其最大值。我们称这个问题是最优化问题的原始问题primal problem。因为这两个函数是等价的，之所以我们需要定义这个函数是因为我们尝试把优化问题中的约束条件融合进原始问题这个无约束函数中。故原始问题的解，就等于优化问题的解。

为什么我们可以用原始问题来代替最优化问题的解？

我们分两个部分来讨论，即：

1. 当x满足约束条件的时候：

<p align="center"> 
  <img src="/imgs/convex/7.png" width="10%" height="10%">
</p>

所以当x满足约束条件的时候，即ci都是小于等于0时，alpha都是大于等于0的，所以在第二行的等式中右边的第二项最大就是0。我们也知道hj是等于0的，所以第三项也就等于0。

2. 当x不满足约束条件的时候：

<p align="center"> 
  <img src="/imgs/convex/8.png" width="80%" height="80%">
</p>

所以当x不满足约束条件的时候，我们的原始问题是趋向于正无穷的。所以无法求得原始问题的最小值。

所以通过以上的推论，我们可以认为如果我们可以找到原始问题的最小值，那么这个值就等价于我们的优化问题。












