---
layout: post
title:  深度学习入门
date:   2020-06-10 00:00:00 +0800
categories: 传智播客
tag: 传智播客
---

* content
{:toc}


## 课程导学

Hello 同学你好，我是杰森老师。欢迎你今天可以跟我一起来探索深度学习的奥秘。我相信打开这门课的你一定听说过人工智能这个词汇，没听过也不要紧～但是你一定知道一些人工智能在现实中的应用。不信？我来举几个你一定知道的例子：

来，打开手机，你的照相机有没有自动美颜？对的，这些所谓的美颜，还有前段时间火过一时的看看自己老年相貌小应用，这些样貌的生成其实都是人工智能的杰作。

<p align="center">
  <img src="/imgs/czbkpics/1.jpg">
</p>

再来举一个例子。百度翻译、有道翻译、谷歌翻译你肯定用过吧，这可不是程序猿一句一句先录入答案的然后再通过你给的句子找到对应的答案哦。它们的背后都是一个人工智能模型在接收我们的输入，然后通过一些神奇的算法再把它觉得最有可能的结果告诉我们。

<p align="center">
  <img src="/imgs/czbkpics/2.png">
</p>

你看，其实人工智能已经默默地潜入到我们的生活了，它可以更好的帮助我们完成我们的目的，让我们的生活变得更加轻松自如。

如今越来越多的岗位逐渐被人工智能取代，但是不用怕，人工智能也为我们创造了更多的岗位，不仅不用害怕找不到工作，而且“钱途”很大有木有～

<p align="center">
  <img src="/imgs/czbkpics/3.png">
</p>


只要你跟着老师上完本次课程，你将会入门人工智能并且可以自己构建一个人工智能模型--教给电脑认数字！

在构建模型前，我们首先看看我们都需要哪些前置知识：
1. 了解深度学习的概念及应用
2. 了解何为深度学习中的“深度”
3. 了解何为深度学习中的“学习”
4. It's ready to 开发自己的深度学习模型！！！

## 第一关 石猴出世

#### 1.1 深度学习的概念

日常生活中我们听到最多的词就是人工智能，但是要注意人工智能并不等于深度学习哦。今日头条为我们绘制了一个图谱。通常来说人工智能包括机器学习、深度学习。它们之间有一定的交集但是我们一定要区分开它们。

<p align="center">
  <img src="/imgs/czbkpics/5.jpg">
</p>

我们所说的深度学习是指由【多层神经网络】所架构的模型。我们在完成一个任务的时候肯定要有的就是输入和输出，比如机器翻译中我们输入中文，输出英文。在神经网络中，我们把它们叫做输入层和输出层。从输入层到输出层之间还会有很多层用来计算，它们负责如何把输入转化为输出。这些中间层我们称为“隐含层”。如果一个神经网络含有**多个**（大于1个）隐含层，我们就管这个网络叫深度神经网络，学习这个模型的过程也就叫做深度学习。因为它在各项任务中表现突出，在越复杂的任务中往往比普通机器学习模型强悍越多，所以日益发展壮大，独成一派。

#### 1.2 深度学习的发展史

我们知道深度学习模型是由深度神经网络架构而成的，神经网络诞生于1943年，但是那个时候因为计算机硬件的落后，更多的概念仅仅停留在学术层面。随着计算机处理器的计算速度和存储越来越强大，在1957-1958年，终于把单层神经网络用在了人工智能应用（模式识别）上，实现了神经网络的第一次兴起。在1986年迎来了两层神经网络，实现了第二次兴起。但是后来又因为CPU算力的不足，人们把精力都放在了普通机器学习模型上，比如KNN，梯度提升树等。终于到了2012年卷积神经网络的诞生，在ImageNet竞赛中秒杀所有普通机器学习模型，迎来了多层神经网络的时代并开启第三次兴起。

<p align="center">
  <img src="/imgs/czbkpics/4.png">
</p>

很荣幸，同学，我们现在就处在神经网络第三次兴起的兴盛阶段！随处可见的人工智能应用已经彻底的潜入我们的生活。

#### 1.3 深度学习随处可见

其实我们身边的很多人工智能应用都属于深度学习的范畴。例如：在商业中的人脸识别，指纹解锁，虹膜认证，自动驾驶，还有对视频内容的提取。在医学中比如肿瘤的识别，健康状况的监控，手术机器人等。这些深度学习模型都跟图像有关，我们管涉及图像的深度学习领域叫做计算机视觉。

<p align="center">
  <img src="/imgs/czbkpics/6.jpeg">
</p>

同样的，在商业中我们还有机器翻译、情感分析、文章摘要提取等；在医学中，我们还可以通过患者对病情和病史的叙述，提取出关键信息，辅助医生为病情作判断等等。这些深度学习模型都和语言文字有关，我们管涉及语言的深度学习领域叫做自然语言处理。

所以说我们的深度学习可以处理两种任务，关于图像的任务和关于语言文字的任务。此刻相信你已经心里有谱了，老师邀请你跟随我一起走进深度学习的世界，并且我们要仅用7行代码实现自己的深度学习模型！



## 闯关练习

1. 下列选项中属于深度学习的模型是：

> A. 单隐含层神经网络
> B. 梯度上升树
> C. KNN
> D. 多隐含层神经网络

正确答案：D，我们管由多个隐含层组成的神经网络叫做深度学习模型。

2. 下列描述中正确的是：

> A. 人工智能包括深度学习
> B. 机器学习包括深度学习
> C. 神经网络包括深度学习
> D. 机器学习不包括神经网络

正确答案：C， 由AI知识图谱我们可以看到，深度学习是完全属于神经网络领域内的。



## 第二关 刨根问底


#### 2.1 神经元

我相信你之前一定听说过【神经元】这个词汇，我们的生物老师告诉我们动物体内的神经元可以传递信号。那你知道计算机世界中的神经元吗？

1943年，神经学家沃伦和逻辑学家沃尔特，发现既然计算机不如我们的大脑，那我们能不能让计算机也模仿大脑进行工作，最起码也要跟我们的大脑一样强嘛！所以他们把动物大脑中的神经网络原封不动地搬到了数学模型中。所以在他们的模型里面，一个简单的人工节点，我们就称为神经元。像动物体内的神经元一样，它也可以帮助我们对输入的信息进行整合并且输出给下一个神经元。

就好比我们的眼睛看到的物体，通过一连串的神经元排排坐，一个转告另一个：
- 神经元A对神经元B说：“喂，老师看到了一个物体，它头发很长，大大的眼睛，还咧着嘴。”
- 神经元B整合信息之后对神经元C说：“喂，老师看到了一个大眼睛的女生，好像还在笑。”
- 神经元C整合信息之后对大脑说：“喂，老师看到一个爱笑的大眼睛女生！”
- 大脑听到后总结地说：“行了我知道了，他看到美女了。”

此时老师拍拍旁边的哥们：“诶你看，美女诶！”

我们管眼睛看到了物体形状叫做【输入】，这个输入可能会很零散，零散到像一堆乐高拼图碎片你根本看不出来它是什么，随着神经元的辛勤整合和传递，我们才能在大脑中产生输出，来判断眼睛看到的是个什么～

再后来1958年Frank Rosenblatt觉得这个思想完全可以创造一个可以识别物体的机器啊，就创建了一套算法，后来人们把这套算法叫做“感知机”，也就是大名鼎鼎的【人工神经网络】。

从此人工神经网络这门学科也被人们称为“仿生学”。

此刻在你大脑里的神经网络应该是这样的：

<p align="center">
  <img src="/imgs/czbkpics/7.png">
</p>

但是问题来了，我们现在只是把输入给到了一个神经元A，可是我们的眼睛看到一个物体是由很多个神经元共同接收信息的呀？别着急，我们完全可以多复制几份呀。

#### 2.2 单层神经网络

我们复制几份后，眼睛看到的物体就由多个神经元共同接收信息了～这就是单层神经网络。
顾名思义，既然是单层，那就是只有一层。如果回到我们上一个老师看美女的例子中：

<p align="center">
  <img src="/imgs/czbkpics/8.png">
</p>

- 神经元A1对大脑说：“老师看到了长长的头发！”
- 神经元A2对大脑说：“老师看到了大大的眼睛！”
- 神经元A3对大脑说：“老师看到了物体咧着嘴！”
- 大脑接收到了神经元们的通知说：“行了我知道了，哎他又看到美女了。”


我们照样还是有一个输入，有一个大脑作为输出，在他们之间我们有一列的神经元排排坐共同接收视觉信息，和上一个例子的区别是这回它们不能沟通！A1不能把自己看到的东西偷偷告诉A2！它们只能把自己看到的东西直接告诉大脑！

这种情况下，我们管蓝色框起来的那一列神经元叫做一层隐含层，所以由输入（眼睛）->一层隐含层->输出（大脑）这样的组合我们就叫做单层神经网络，也叫单层感知机。

是不是很简单，但是别看它的结构很简单，它的能力是很强的。在数学中它还有一套定理叫做【万能近似定理】，指的是如果你手头上有一个包含一层隐含层的网络结构，只要你这一层有足够多的神经元排排坐（例如有50个/100个/...），那么你这个神经网络就可以做到任何的事情！

厉害吧，可是如果你对神经网络有所了解或者你偷偷看到了后面的内容，就不禁会有一个疑问：既然单层神经网络已经这么厉害了，我们为什么还要有多层神经网络呢？

直击灵魂深处的答案：我是说过你有这个能力，但是你未必能做到啊。

一万匹草泥马呼啸而过。OK吧，那既然我一个人未必能达到，我找几个小伙伴组团就简单很多了吧。于是单层神经网络就变成了多层神经网络。

#### 2.3 多层神经网络

我们此时选中第一层神经元A1-A3，右键复制粘贴重命名为神经元B1-B3:

<p align="center">
  <img src="/imgs/czbkpics/9.png">
</p>

每一层的神经元我们让它都跟下一层的所有神经元相连接。这种连接方式我们叫做**全连接**。此时我们已经有了一个2层神经网络。当然你可以随意的复制很多层，但是！

在一项工作中，如果只有你一个人做，你未必能考虑的很全面；可是如果有很多人来做，你们可能会因为意见冲突打起来反而事与愿违。所以虽然多层神经网络要比单层更有优势，但是也不要贪心哦，未必层数越多你的神经网络能力就会越强。

所谓深度学习，先深度后学习，我们已经了解了什么是深度--【多层神经网络】，那同学想知道神经网络是如何学习的么？

## 闯关练习

1. 在神经网络中每个神经元的作用是什么？（多选题）

> A. 接收传递过来的信息
> B. 保存参数
> C. 发送整合后的信息给下一个神经元
> D. 信息整合

正确答案：A,C,D 神经元的作用是接收前面神经元传递过来的信息并且整合之后再传递给下一个神经元。


2. 在单层神经网络中，下面表述正确的是：

> A. 一层中每个神经元相互连接
> B. 有学习到最佳参数的能力
> C. 没有学习到最佳参数的能力
> D. 一定不如多层神经网络

正确答案：B 无论是几层的网络，同一层的神经元之间不相互连接；单层神经网络有学习到最佳参数的能力；神经网络的好坏不取决于有多少层，10层的神经网络未必就有1层的神经网络好。

3. 在多层神经网络中，下面表述错误的是：

> A. 每个神经元只跟下一层的某个神经元相连
> B. 网络的参数可以用梯度下降法来求解
> C. 第i层的某个神经元接收自i-1层所有的神经元传递来的信息
> D. 梯度下降法求解只能求得近似解

正确答案：A 每个神经元都跟下一层的所有神经元相连接。梯度下降法是用迭代的方式一步一步的逼近真实解，所以大多数情况下我们只能得到近似解。



## 第三关 打开黑盒

#### 3.1 神经网络的参数

为了解释这个疑问，我们要引入神经网络“参数”这个概念。一元一次方程学过不，3x=30 求解x？太简单了啊x=10。

在神经网络中我们的参数就是这个x！其中一个神经元上的值为3，另一个为30，那么转化过程就是乘以10。

<p align="center">
  <img src="/imgs/czbkpics/19.png">
</p>

所以在神经网络中，我们每两个神经元之间的连线上都是有一个参数的，这个参数告诉我们如何把一个神经元转化成另外一个。如果我们显示的标记上每个转化过程的参数x就会变成这样：

<p align="center">
  <img src="/imgs/czbkpics/20.png">
</p>

是不是眼花缭乱了？此刻你还能口算出所有x的值嘛？所以神经网络做的事情，就是把我们人类不能在脑子里计算出来的参数，帮助我们计算出来。

但是很遗憾的是计算机也无法准确计算出来。。小朋友你是不是有很多问号了？虽然无法计算出来，但是计算机可以帮助我们找到一个特别特别接近正确值的x，这样就算方程本身是无解的，也还可以无限的去接近它。
这个估计的过程也是相当简单，猜数字玩过没有？


#### 3.2 寻找参数

接下来是我国著名幼儿园课堂游戏--猜数字。

规则是这样的：老师心里默想一个数字，由同学来猜。如果同学猜的数字大于老师的，老师会说“高了”。相反，老师会说“低了”。

在这个过程中同学一般无法在第一轮就猜到老师的数字，但是随着提示轮次越多，就会越来越接近老师的数字。

在神经网络的**训练**过程中，由于大脑是提前知道标准答案的，所以我们让大脑担任老师的角色，让所有神经元担任学生的角色。这样一来一往，所有的神经元之间的参数都会慢慢的靠近标准答案。这个方法的专业名称叫做【梯度下降法】。

它是通过一轮一轮迭代的过程，让未知数慢慢的靠近标准答案，直到大脑说：“你们已经都猜到了！”

了解了怎么训练神经网络之后，我们就可以开始动手去实现自己的深度学习模型了。我们不需要担心怎么去实现梯度下降，甚至我们连隐含层都不需要知道怎么用代码实现。因为这些固定的结构早已有前辈为我们写好了，所以做出一个自己的模型，我们只要调用前辈写好的库就够了。

接下来我们要使用在工业界用的最多的一个框架--Tensorflow，它强大到可以让我们在5行代码之内搭建出深度学习模型。使用方法也是异常的简单～



## 闯关练习

1. 下列关于神经网络参数说法中正确的是：

> A. 参数是需要我们自己设置的
> B. 参数可以被精准计算出来
> C. 参数是需要神经网络学习估计出来的
> D. 参数的解是唯一的

正确答案：C 参数是被神经网络学习出来的，但是绝大部分情况下只能求得近似解，所以也导致了参数的解也许有很多个。


2. 在参数训练过程中，下面表述正确的是：

> A. 参数训练不依靠真实值
> B. 参数训练可以一次性找到解
> C. 参数训练通过迭代的方法逐步逼近真实值

正确答案：C 参数的训练过程是一步一步的向着真实值靠近，所以也是需要真实值来引导方向的。




## 第四关 xxxxxx

#### 4.1 Tensorflow的安装

在安装我们的框架前，我们要保证我们已经有了python的编译环境。如果你还没有安装python，可以通过官网（https://www.python.org/）下载或者通过下载Anaconda（https://www.anaconda.com/）它会自带python环境。要注意我们用的是Tensorflow 2，所以它要求我们的python版本在3.5以上。

安装好python之后，如果你是通过官网下载的，我们可以直接在命令行输入以下命令就安装好Tensorflow啦。

```
# 如果你是通过官网下载的，就输入以下一行命令

pip install tensorflow

# 如果你是通过Anaconda下载的，下面的两行命令会为你创建一个Tensorflow的虚拟环境并且激活这个虚拟环境

conda create -n tf tensorflow            # 创建名为tf的虚拟环境，在虚拟环境下安装Tensorflow
conda activate tf                        # 激活名为tf的虚拟环境
```


安装好后，我们还需要一个代码编辑器，如果你有自己习惯的编辑器可以直接使用，如果没有偏好的话老师建议下载一个Jupyter notebook。下载Jupyter notebook也很简单：

```
# 如果你是官网下载的python，那么在命令行输入以下两行命令

pip install jupyterlab
pip install notebook

# 如果你是用Anaconda下载的，那么输入以下两行命令

conda install -c conda-forge jupyterlab
conda install -c conda-forge notebook
```

然后就完成啦，我们可以用命令行输入以下命令打开编辑器：

```
jupyter notebook
```

打开后我们可以检查一下是否安装成功了Tensorflow，在输入以下两行后点击上面的“Run”按钮，它就会执行当前的代码块:

<p align="center">
  <img src="/imgs/czbkpics/11.png">
</p>

如果运行结果跟老师的一样说明同学你已经成功配置完所有环境啦。

#### 4.2 Tensorflow项目前预备知识

Tensorflow已经为我们封装好了所有我们需要的库，包括我们的数据集也可以直接从Tensorflow下载得到。
我们要做的就是给电脑一张图片，每张图片上是手写版的阿拉伯数字0-9，我们想让计算机通过深度学习之后，帮我们预测随机的一张图片上面的数字是几。

<p align="center">
  <img src="/imgs/czbkpics/12.png">
</p>


好了，我们可以通过
```
(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()
```

我们考试之前的复习阶段，都是要有题目和答案的，神经网络学习也是一样的，我们管复习的题库叫做【训练集】，它包含题目x_train和标准答案y_train。

复习完之后我们就要考试了，我们管这个试卷叫做【测试集】。考试的时候你只能知道题目x_test，y_test是老师用来看你的学习成果给你打分的～我们总共有60000条训练数据和10000条测试数据。

接下来我们要为神经网络的输入做一个准备，我们知道图片都是由像素点组成的，就像用不同颜色的钉子拼出蒙娜丽莎的微笑。在我们的数据里每幅图都有28*28=784个像素点，我们现在把这些像素点拉平，形成一个一行784列的列表，就像下图一样：

<p align="center">
  <img src="/imgs/czbkpics/13.png">
</p>

同时我们再把每个点上的值都除以255，让它们保证在0-1之间方便计算机计算。

```
# reshape可以帮助我们得到想要的形状

x_train = x_train.reshape(60000, 784).astype('float32') / 255
x_test = x_test.reshape(10000, 784).astype('float32') / 255
```

好了，我们已经准备好了输入，接下来就是激动人心的架构神经网络了！

搭积木我相信同学你肯定玩过，想搭一间屋子我们就得一块一块的砖头往上累。在Tensorflow里搭神经网络也是一模一样的方式，首先我们要圈一块地，Tensorflow中我们用Sequential来声明这块地是属于我的了，用layers.Dense表示这是一个神经网络的隐含层，那么我们如果想要这个神经网络有3层，就可以直接复制三份layers.Dense在Sequential容器内：


```
model = tf.keras.models.Sequential([
  tf.keras.layers.Dense(32),
  tf.keras.layers.Dense(64),
  tf.keras.layers.Dense(10, activation='softmax')
])

```
layers.Dense(32)表示我们的第一层一共有32个神经元，第二层有64个。
最后我们要一个输出层，要10个神经元，对应0-9的每个数字，每个神经元都通过一个叫softmax的函数帮助我们计算了它对应的数字的概率，我们的整个神经网络就长成这个样子，比如说对应数字8的神经元概率最大，那预测的结果就会是8。

<p align="center">
  <img src="/imgs/czbkpics/14.png">
</p>

好了我们已经把神经网络搭建完了。现在我们要告诉它你要用猜数字的方式来学习参数，通过设置optimizer='sgd'。
我们还需要告诉大脑你要用“sparse_categorical_crossentropy”的方法来告诉他们离标准答案还有多远。最后我们要告诉模型我们的目标是提高准确率accuracy。

```
model.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
```

大功告成！接下来就是训练我们搭建的模型了！我们直接用fit函数，并且传给它我们训练集的题目和答案，他就可以自己学习了！

```
model.fit(x_train, y_train, epochs=5)
```

想考高分题目刷一遍哪里够？所以这里我们额外设置epochs=5，让模型自己反复的给我学个5遍！

运行！模型会实时的给我们汇报它学习的成果:

<p align="center">
  <img src="/imgs/czbkpics/15.png">
</p>

我们发现随着刷题轮数越多，我们的accuracy准确率也从一开始的84%提升到了91.8%。

好啦，学完之后我们就要开始考试了！我们可以从测试集里随机抽取5道题看看学习效果。这里老师为了让同学能直观的看到图片上的数字，用了matplotlib进行了绘画，如果你也想自己动手画一画不要忘记安装matplotlib哦。

<p align="center">
  <img src="/imgs/czbkpics/16.png">
</p>

我们随机挑选了5张图片，分别是7、2、1、0、4。我们来看看模型认不认得这些数字，用模型名.predict函数进行预测：

```
prediction = model.predict(x_test[:5]) # 给出我们之前画的5张图
```

现在prediction里面已经有了对于每个图片，它分别是0-9每个数字的概率，我们为了更清晰的看到答案，老师直接打印出来每个图片对应最高概率的是几：

<p align="center">
  <img src="/imgs/czbkpics/17.png">
</p>

Bingo!全对！虽然学习之后准确率大约92%，但是对于这5张图片我们的模型还是很有自信的嘛。

好啦，现在同学可以自己对我们的模型稍加修改，比如再多几层隐含层，看看能不能超越老师。

## 课程总结

<p align="center">
  <img src="/imgs/czbkpics/18.png">
</p>

我们在本节课中介绍了深度学习是人工智能的子领域，也了解了神经网络的组成成分--神经元。我们把很多个神经元放在一起，就变成了单层神经网络，把很多个单层神经网络放在一起就变成了多层神经网络！深度学习也正是大于一个隐含层的神经网络模型。再后来我们知道了虽然是多层神经网络，对于不同的任务也有不同的结构。卷积神经网络多用于计算机视觉，可以帮助我们提取到图片的局部信息；循环神经网络多用于自然语言处理，可以帮助我们提取到上下文的全局信息。当然还有一些其他的种类同学可以课下去探索一下。最后我们用当下最流行的深度学习框架Tensorflow自己手动实现了一个多层神经网络，教会了计算机认数字。

老师想给你留一个课后作业，在项目中我们选择了adam的学习方法，试着找一找还有没有其他的？

相信你已经感受到了深度学习的魅力。前路漫漫，时代在进步，深度学习的领域发展尚未完全，还有很多的未知等着我们去探索，老师欢迎你的加入！


